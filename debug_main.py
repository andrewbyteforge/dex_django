from __future__ import annotations
import asyncio
import json
import logging
import random
import os
import sys
from datetime import datetime, timezone, timedelta
from decimal import Decimal
from typing import Dict, Any, List, Set, Optional
from concurrent.futures import ThreadPoolExecutor
from fastapi import FastAPI, APIRouter, WebSocket, WebSocketDisconnect, Query, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# ============================================================================
# SYSTEM INITIALIZATION - Setup paths and dependencies
# ============================================================================

# Add to path BEFORE importing apps modules
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Install aiohttp if not already available
try:
    import aiohttp
except ImportError:
    import subprocess
    import sys
    subprocess.check_call([sys.executable, "-m", "pip", "install", "aiohttp"])
    import aiohttp

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("debug_main")

# ============================================================================
# GLOBAL STATE - WebSocket connections and system state
# ============================================================================

# Global state for WebSocket connections
paper_clients: Set[WebSocket] = set()
metrics_clients: Set[WebSocket] = set()
thought_log_active = False
executor = ThreadPoolExecutor(max_workers=2)

# ============================================================================
# DJANGO SETUP - Initialize Django ORM for database access
# ============================================================================

def setup_django():
    """Initialize Django ORM for database access."""
    try:
        # Add the dex_django directory to Python path
        project_root = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'dex_django')
        if project_root not in sys.path:
            sys.path.insert(0, project_root)
        
        # Configure Django settings BEFORE importing django
        if not os.environ.get('DJANGO_SETTINGS_MODULE'):
            os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'dex_django.settings')
        
        # NOW import django after environment is set
        import django
        from django.conf import settings
        
        # Only setup if not already configured
        if not settings.configured:
            django.setup()
        
        logger.info("Django ORM initialized successfully")
        return True
    except Exception as e:
        logger.error(f"Failed to initialize Django: {e}")
        # Add full traceback for debugging
        import traceback
        logger.error(f"Full traceback: {traceback.format_exc()}")
        return False

# Initialize Django before importing apps
django_initialized = setup_django()

# ============================================================================
# MODULE IMPORTS - Import optional modules with proper error handling
# ============================================================================

# Try to import copy_mock module
try:
    from apps.api import copy_mock
    copy_mock_available = True
    logger.info("copy_mock router loaded")
except Exception as e:
    copy_mock_available = False
    logger.warning(f"copy_mock router unavailable: {e}")

# Try to import copy trading modules with proper error handling
copy_trading_ready = False
try:
    if django_initialized:
        # Import copy trading backend modules
        from backend.app.discovery.wallet_monitor import wallet_monitor
        from backend.app.strategy.copy_trading_strategy import copy_trading_strategy
        from backend.app.ws.copy_trading import copy_trading_hub
        from backend.app.api.copy_trading import router as copy_trading_api_router
        
        # Import Django models
        from dex_django.apps.storage.models import FollowedTrader, CopyTrade, CopyTradeFilter
        
        copy_trading_ready = True
        logger.info("Full copy trading system imported successfully")
    else:
        logger.warning("Django not initialized, copy trading unavailable")
except ImportError as e:
    logger.warning(f"Copy trading modules not available: {e}")
except Exception as e:
    logger.error(f"Copy trading module import failed: {e}")

# Legacy copy trading engine import
copy_trading_available = False
try:
    if django_initialized:
        from apps.intelligence.copy_trading_engine import copy_trading_engine
        copy_trading_available = True
        logger.info("Legacy copy trading engine imported successfully")
except ImportError as e:
    logger.warning(f"Legacy copy trading engine not available: {e}")
except Exception as e:
    logger.error(f"Legacy copy trading engine import failed: {e}")

# ============================================================================
# HEALTH ROUTER - System health and status endpoints
# ============================================================================

health_router = APIRouter()

@health_router.get("/health")
async def health():
    """Return system health status including all subsystems."""
    return {
        "status": "ok", 
        "timestamp": datetime.now().isoformat(), 
        "debug": True,
        "copy_trading_ready": copy_trading_ready,
        "copy_trading_available": copy_trading_available,
        "services": {
            "django": django_initialized,
            "wallet_monitor": copy_trading_ready,
            "copy_trading_hub": copy_trading_ready
        }
    }

# ============================================================================
# API ROUTER - Main API endpoints
# ============================================================================

api_router = APIRouter(prefix="/api/v1")

class ToggleRequest(BaseModel):
    enabled: bool

# ============================================================================
# PAPER TRADING ENDPOINTS - Virtual trading system
# ============================================================================

@api_router.post("/paper/toggle")
async def toggle_paper(request: ToggleRequest):
    """Toggle Paper Trading and broadcast status to connected clients."""
    global thought_log_active
    thought_log_active = request.enabled
    
    # Broadcast status to all paper clients
    status_message = {
        "type": "paper_status",
        "timestamp": datetime.now(timezone.utc).isoformat(),
        "payload": {
            "paper_enabled": request.enabled,
            "thought_log_active": thought_log_active
        }
    }
    await broadcast_to_paper_clients(status_message)
    
    if request.enabled:
        # Start AI Thought Log streaming
        asyncio.create_task(start_thought_log_stream())
    
    return {"status": "ok", "paper_enabled": request.enabled}

@api_router.get("/metrics/paper")
async def metrics_paper():
    """Get paper trading metrics and performance data."""
    return {
        "status": "ok", 
        "metrics": {
            "session_pnl_usd": 125.50,
            "total_trades": 8,
            "win_rate": 0.75,
            "avg_slippage_bps": 12,
            "max_drawdown": -45.25,
            "active_since": datetime.now().isoformat(),
            "debug": True
        }
    }

@api_router.post("/paper/thought-log/test")
async def paper_thought_log_test():
    """Emit a test AI Thought Log message."""
    test_thought = generate_mock_thought_log()
    await broadcast_thought_log(test_thought)
    return {"status": "ok", "message": "Test thought log emitted"}

# ============================================================================
# COPY TRADING ENDPOINTS - Copy trading system management
# ============================================================================

@api_router.get("/copy/status")
async def get_copy_trading_status():
    """Get copy trading system status with required system_status field."""
    if not copy_trading_ready:
        return {
            "status": "ok",
            "copy_trading_enabled": False,
            "message": "Copy trading system not available",
            "system_status": {
                "total_trades": 0,
                "winning_trades": 0,
                "total_pnl_usd": 0.0,
                "win_rate_pct": 0.0,
                "active_copies": 0,
                "tracked_traders": 0
            },
            "services": {
                "wallet_monitor": False,
                "copy_trading_hub": False,
                "django_models": django_initialized
            }
        }
    
    try:
        # Get monitoring status from wallet monitor
        monitoring_status = await wallet_monitor.get_monitoring_status()
        
        # Get followed traders count from Django database
        traders_count = FollowedTrader.objects.filter(status='active').count()
        
        # Get recent copy trades from last 24 hours
        recent_trades = CopyTrade.objects.filter(
            created_at__gte=datetime.now(timezone.utc) - timedelta(hours=24)
        ).count()
        
        # Calculate system status metrics
        total_trades = CopyTrade.objects.count()
        successful_trades = CopyTrade.objects.filter(status='executed', is_profitable=True).count()
        win_rate = (successful_trades / total_trades * 100) if total_trades > 0 else 0.0
        
        return {
            "status": "ok",
            "copy_trading_enabled": True,
            "monitoring_status": monitoring_status,
            "followed_traders": traders_count,
            "trades_24h": recent_trades,
            "hub_running": copy_trading_hub._is_running,
            "system_status": {
                "total_trades": total_trades,
                "winning_trades": successful_trades,
                "total_pnl_usd": 1250.30,  # Would calculate from actual data
                "win_rate_pct": win_rate,
                "active_copies": CopyTrade.objects.filter(status='pending').count(),
                "tracked_traders": traders_count
            },
            "services": {
                "wallet_monitor": True,
                "copy_trading_hub": True,
                "django_models": True
            }
        }
    except Exception as e:
        logger.error(f"Copy trading status error: {e}")
        return {
            "status": "ok", 
            "copy_trading_enabled": False,
            "message": str(e),
            "system_status": {
                "total_trades": 0,
                "winning_trades": 0,
                "total_pnl_usd": 0.0,
                "win_rate_pct": 0.0,
                "active_copies": 0,
                "tracked_traders": 0
            }
        }

@api_router.post("/copy/toggle")
async def toggle_copy_trading(request: ToggleRequest):
    """Toggle copy trading system on/off."""
    if not copy_trading_ready:
        return {
            "status": "error",
            "message": "Copy trading system not available"
        }
    
    try:
        if request.enabled:
            # Get active traders and start monitoring their wallets
            active_traders = FollowedTrader.objects.filter(status='active')
            if active_traders.exists():
                wallet_addresses = [trader.wallet_address for trader in active_traders]
                await wallet_monitor.start_monitoring(wallet_addresses)
            
            # Start copy trading hub if not running
            if not copy_trading_hub._is_running:
                await copy_trading_hub.start()
        else:
            # Stop monitoring and hub
            await wallet_monitor.stop_monitoring()
            await copy_trading_hub.stop()
        
        return {
            "status": "ok",
            "copy_trading_enabled": request.enabled,
            "message": f"Copy trading {'enabled' if request.enabled else 'disabled'}"
        }
    except Exception as e:
        logger.error(f"Copy trading toggle error: {e}")
        return {
            "status": "error",
            "message": str(e)
        }

@api_router.get("/copy/traders")
async def list_followed_traders(
    page: int = Query(1, ge=1),
    limit: int = Query(10, ge=1, le=50)
):
    """List followed traders with pagination."""
    if not copy_trading_ready:
        return {
            "status": "ok",
            "data": [],
            "pagination": {"page": page, "limit": limit, "total": 0, "pages": 0}
        }
    
    try:
        # Get traders with pagination from database
        traders = FollowedTrader.objects.all().order_by('-created_at')
        total_count = traders.count()
        
        # Apply pagination limits
        start_idx = (page - 1) * limit
        end_idx = start_idx + limit
        paginated_traders = traders[start_idx:end_idx]
        
        # Format trader data for API response
        traders_data = []
        for trader in paginated_traders:
            traders_data.append({
                "id": str(trader.id),
                "wallet_address": trader.wallet_address,
                "trader_name": trader.trader_name,
                "status": trader.status,
                "copy_mode": trader.copy_mode,
                "copy_percentage": float(trader.copy_percentage),
                "total_copies": trader.total_copies,
                "successful_copies": trader.successful_copies,
                "win_rate": trader.win_rate_pct,
                "total_pnl_usd": float(trader.total_pnl_usd),
                "created_at": trader.created_at.isoformat(),
                "last_activity_at": trader.last_activity_at.isoformat() if trader.last_activity_at else None
            })
        
        return {
            "status": "ok",
            "data": traders_data,
            "pagination": {
                "page": page,
                "limit": limit,
                "total": total_count,
                "pages": (total_count + limit - 1) // limit,
                "has_next": end_idx < total_count,
                "has_prev": page > 1
            }
        }
    except Exception as e:
        logger.error(f"List traders error: {e}")
        return {
            "status": "ok",
            "data": [],
            "pagination": {"page": page, "limit": limit, "total": 0, "pages": 0}
        }

@api_router.get("/copy/trades")
async def get_copy_trades(
    page: int = Query(1, ge=1),
    limit: int = Query(20, ge=1, le=100),
    status: Optional[str] = Query(None)
):
    """Get copy trade history with optional status filter."""
    if not copy_trading_ready:
        return {
            "status": "ok", 
            "data": [],
            "pagination": {"page": page, "limit": limit, "total": 0, "pages": 0}
        }
    
    try:
        # Build database query with optional status filter
        trades = CopyTrade.objects.all().select_related('followed_trader').order_by('-created_at')
        
        if status:
            trades = trades.filter(status=status)
        
        total_count = trades.count()
        
        # Apply pagination
        start_idx = (page - 1) * limit
        end_idx = start_idx + limit
        paginated_trades = trades[start_idx:end_idx]
        
        # Format trade data for API response
        trades_data = []
        for trade in paginated_trades:
            trades_data.append({
                "id": str(trade.id),
                "followed_trader_address": trade.followed_trader.wallet_address,
                "trader_name": trade.followed_trader.trader_name,
                "original_tx_hash": trade.original_tx_hash,
                "chain": trade.chain,
                "dex_name": trade.dex_name,
                "token_symbol": trade.token_symbol,
                "original_amount_usd": float(trade.original_amount_usd),
                "copy_amount_usd": float(trade.copy_amount_usd),
                "status": trade.status,
                "copy_tx_hash": trade.copy_tx_hash,
                "execution_delay_seconds": trade.execution_delay_seconds,
                "pnl_usd": float(trade.pnl_usd) if trade.pnl_usd else None,
                "is_paper": trade.is_paper,
                "created_at": trade.created_at.isoformat()
            })
        
        return {
            "status": "ok",
            "data": trades_data,
            "pagination": {
                "page": page,
                "limit": limit,
                "total": total_count,
                "pages": (total_count + limit - 1) // limit,
                "has_next": end_idx < total_count,
                "has_prev": page > 1
            }
        }
    except Exception as e:
        logger.error(f"Get copy trades error: {e}")
        return {
            "status": "ok",
            "data": [],
            "pagination": {"page": page, "limit": limit, "total": 0, "pages": 0}
        }

# ============================================================================
# DISCOVERY ENDPOINTS - Token pair discovery system
# ============================================================================

@api_router.get("/discovery/status")
async def discovery_status():
    """Get discovery engine status and configuration."""
    return {
        "status": "ok",
        "discovery": {
            "enabled": True,
            "running": False,
            "last_scan": None,
            "scan_interval_seconds": 5,
            "min_liquidity_usd": 5000.0,
            "chains_enabled": ["ethereum", "bsc", "base", "polygon"],
            "dexes_enabled": ["uniswap_v2", "uniswap_v3", "pancake_v2", "quickswap"],
            "pairs_discovered_today": 0,
            "significant_opportunities": []
        }
    }

@api_router.post("/discovery/start")
async def discovery_start():
    """Start discovery engine."""
    return {
        "status": "ok",
        "message": "Discovery engine started",
        "running": True
    }

@api_router.post("/discovery/stop") 
async def discovery_stop():
    """Stop discovery engine."""
    return {
        "status": "ok",
        "message": "Discovery engine stopped",
        "running": False
    }

# ============================================================================
# OPPORTUNITIES ENDPOINTS - Live trading opportunities
# ============================================================================

@api_router.get("/opportunities/live")
async def get_live_opportunities(
    page: int = Query(1, ge=1, description="Page number"),
    limit: int = Query(20, ge=1, le=100, description="Results per page")
):
    """Get live opportunities from real APIs with pagination."""
    try:
        logger.info(f"Fetching live opportunities (page {page}, limit {limit})...")
        # Fetch opportunities from multiple real API sources
        all_opportunities = await fetch_real_opportunities()
        
        # Apply pagination to the results
        total_count = len(all_opportunities)
        start_idx = (page - 1) * limit
        end_idx = start_idx + limit
        paginated_opportunities = all_opportunities[start_idx:end_idx]
        
        # Format opportunities for frontend consumption
        formatted_opportunities = []
        for opp in paginated_opportunities:
            formatted_opp = {
                "id": hash(opp.get("pair_address", "")) % 1000000,
                "base_symbol": opp.get("token0_symbol", "UNKNOWN"),
                "quote_symbol": opp.get("token1_symbol", "UNKNOWN"), 
                "address": opp.get("pair_address", ""),
                "chain": opp.get("chain", "unknown"),
                "dex": opp.get("dex", "unknown"),
                "source": opp.get("source", "unknown"),
                "liquidity_usd": float(opp.get("estimated_liquidity_usd", 0)),
                "score": float(opp.get("opportunity_score", 0)),
                "time_ago": "Live",
                "created_at": opp.get("timestamp", datetime.now().isoformat()),
                "risk_flags": []
            }
            formatted_opportunities.append(formatted_opp)
        
        logger.info(f"Returning page {page} with {len(formatted_opportunities)} opportunities (total: {total_count})")
        
        return {
            "status": "ok",
            "opportunities": formatted_opportunities,
            "count": len(formatted_opportunities),
            "total": total_count,
            "page": page,
            "pages": (total_count + limit - 1) // limit,
            "limit": limit,
            "last_updated": datetime.now(timezone.utc).isoformat()
        }
        
    except Exception as e:
        logger.error(f"Live opportunities error: {e}")
        return {
            "status": "ok",
            "opportunities": [],
            "count": 0,
            "total": 0,
            "page": page,
            "pages": 0,
            "limit": limit,
            "last_updated": datetime.now(timezone.utc).isoformat()
        }

@api_router.get("/opportunities/stats")
async def get_opportunity_stats():
    """Get opportunity statistics from live data."""
    try:
        logger.info("Calculating opportunity stats...")
        # Fetch current opportunities and calculate real statistics
        opportunities = await fetch_real_opportunities()
        stats = calculate_real_stats(opportunities)
        return {"status": "ok", "stats": stats}
    except Exception as e:
        logger.error(f"Stats error: {e}")
        return {
            "status": "ok",
            "stats": {
                "total_opportunities": 0,
                "high_liquidity_opportunities": 0,
                "chains_active": 0,
                "average_liquidity_usd": 0
            }
        }

# ============================================================================
# ANALYZE ENDPOINT - NEW! Detailed opportunity analysis
# ============================================================================

@api_router.post("/opportunities/analyze")
async def analyze_opportunity(request_data: dict):
    """
    Analyze a specific trading opportunity with comprehensive metrics.
    
    This is the MISSING ENDPOINT that the frontend analyze button calls.
    It provides detailed analysis including:
    - Liquidity depth analysis
    - Risk assessment 
    - Token contract analysis
    - Trading signals and momentum
    - AI-generated recommendations
    """
    try:
        logger.info(f"Analyzing opportunity: {request_data.get('pair_address', 'unknown')}")
        
        # Extract request parameters
        pair_address = request_data.get("pair_address", "")
        chain = request_data.get("chain", "ethereum")
        dex = request_data.get("dex", "unknown")
        trade_amount_eth = request_data.get("trade_amount_eth", 0.1)
        
        # Generate comprehensive analysis data (currently mocked, would be real analysis)
        analysis = {
            # Basic pair information
            "pair_info": {
                "address": pair_address,
                "chain": chain,
                "dex": dex,
                "analyzed_at": datetime.now(timezone.utc).isoformat(),
                "trace_id": f"analysis_{random.randint(1000, 9999)}"
            },
            
            # Liquidity depth and trading volume analysis
            "liquidity_analysis": {
                "current_liquidity_usd": random.randint(50000, 500000),
                "liquidity_depth_5pct": random.randint(5000, 25000),  # Available liquidity at 5% price impact
                "liquidity_depth_10pct": random.randint(10000, 50000),  # Available liquidity at 10% price impact
                "liquidity_stability_24h": random.choice(["stable", "volatile", "declining"]),
                "volume_24h_usd": random.randint(20000, 200000),
                "volume_to_liquidity_ratio": round(random.uniform(0.1, 2.0), 3),
                "large_holder_risk": random.choice(["low", "medium", "high"])
            },
            
            # Smart contract and security risk assessment
            "risk_assessment": {
                "risk_score": round(random.uniform(2.0, 9.5), 1),  # Overall risk score out of 10
                "risk_level": random.choice(["low", "medium", "high"]),
                "contract_verification": random.choice(["verified", "unverified"]),
                "honeypot_risk": random.choice(["low", "medium", "high"]),
                "liquidity_locked": random.choice([True, False]),  # Is liquidity locked in contract
                "lock_duration_days": random.randint(30, 365) if random.choice([True, False]) else None,
                "owner_can_mint": random.choice([True, False]),  # Can owner mint new tokens
                "trading_cooldown": random.choice([True, False])  # Are there trading restrictions
            },
            
            # Token contract analysis
            "token_analysis": {
                "total_supply": random.randint(1000000, 1000000000),
                "circulating_supply": random.randint(500000, 900000000),
                "market_cap": random.randint(100000, 10000000),
                "token_age_days": random.randint(1, 365),
                "holder_count": random.randint(100, 10000),
                "top_holder_percentage": round(random.uniform(0.05, 0.30), 3),  # Percentage held by largest holder
                "buy_tax": round(random.uniform(0.0, 0.10), 3),  # Tax on purchases
                "sell_tax": round(random.uniform(0.0, 0.10), 3),  # Tax on sales
                "transfer_tax": round(random.uniform(0.0, 0.05), 3),  # Tax on transfers
                # Contract features that could affect trading
                "contract_features": {
                    "pausable": random.choice([True, False]),  # Can trading be paused
                    "mintable": random.choice([True, False]),  # Can new tokens be minted
                    "burnable": random.choice([True, False]),  # Can tokens be burned
                    "proxy": random.choice([True, False])  # Is this a proxy contract
                }
            },
            
            # Technical analysis and trading signals
            "trading_signals": {
                "momentum_score": round(random.uniform(3.0, 9.5), 1),  # Price momentum out of 10
                "technical_score": round(random.uniform(4.0, 8.5), 1),  # Technical indicators score
                "trend_direction": random.choice(["bullish", "bearish", "neutral"]),
                "volume_trend": random.choice(["increasing", "decreasing", "stable"]),
                "social_sentiment": random.choice(["positive", "negative", "neutral"]),
                "whale_activity": random.choice(["buying", "selling", "neutral"]),  # Large holder activity
                "support_level": round(random.uniform(0.000001, 0.01), 6),  # Price support level
                "resistance_level": round(random.uniform(0.000001, 0.01), 6)  # Price resistance level
            },
            
            # AI-generated trading recommendation
            "recommendation": {
                "action": random.choice(["BUY", "SELL", "HOLD", "MONITOR"]),  # Recommended action
                "confidence": round(random.uniform(0.4, 0.95), 2),  # AI confidence level
                "position_size": random.choice(["small", "medium", "large"]),  # Recommended position size
                "entry_strategy": random.choice(["market", "limit", "dca"]),  # How to enter position
                "stop_loss": round(random.uniform(0.05, 0.20), 3),  # Recommended stop loss percentage
                "take_profit_1": round(random.uniform(0.10, 0.30), 3),  # First profit target
                "take_profit_2": round(random.uniform(0.25, 0.50), 3),  # Second profit target
                "max_slippage": round(random.uniform(0.01, 0.05), 3),  # Maximum acceptable slippage
                "gas_priority": random.choice(["low", "medium", "high"]),  # Gas price priority
                # Detailed explanation of the recommendation
                "rationale": "Analysis based on liquidity depth, technical indicators, and risk assessment. " + 
                           random.choice([
                               "Strong momentum signals detected with acceptable risk levels.",
                               "Moderate opportunity with standard risk parameters.",
                               "High volatility detected, proceed with caution.",
                               "Limited liquidity may impact execution quality."
                           ])
            }
        }
        
        logger.info(f"Analysis complete for {pair_address}: {analysis['recommendation']['action']}")
        
        return {
            "status": "ok",
            "analysis": analysis,
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
        
    except Exception as e:
        logger.error(f"Analysis failed: {e}")
        return {
            "status": "error",
            "error": f"Analysis failed: {str(e)}",
            "timestamp": datetime.now(timezone.utc).isoformat()
        }

# ============================================================================
# COMPATIBILITY ENDPOINTS - For Django ORM compatibility
# ============================================================================

@api_router.get("/tokens/")
async def get_tokens(page: int = Query(1, ge=1), limit: int = Query(50, ge=1, le=100)):
    """Get tokens list (compatibility endpoint)."""
    return {"status": "ok", "data": [], "pagination": {"page": page, "limit": limit, "total": 0, "pages": 0}}

@api_router.get("/trades/")
async def get_trades(page: int = Query(1, ge=1), limit: int = Query(50, ge=1, le=100)):
    """Get trades list (compatibility endpoint)."""
    return {"status": "ok", "data": [], "pagination": {"page": page, "limit": limit, "total": 0, "pages": 0}}

@api_router.get("/providers/")
async def get_providers():
    """Get data providers list (compatibility endpoint)."""
    return {"status": "ok", "data": [{"id": 1, "name": "Debug Provider", "enabled": True, "kind": "rpc"}], "count": 1}

@api_router.get("/bot/status")
async def get_bot_status():
    """Get trading bot status (compatibility endpoint)."""
    return {"status": "ok", "data": {"status": "running", "uptime_seconds": 3600, "total_trades": 0, "paper_mode": True, "debug": True}}

@api_router.get("/intelligence/status")
async def get_intelligence_status():
    """Get AI intelligence system status (compatibility endpoint)."""
    return {"status": "ok", "data": {"enabled": True, "advanced_risk_enabled": True, "mempool_monitoring_enabled": False, "debug": True}}

# ============================================================================
# WEBSOCKET ROUTER - Real-time communication
# ============================================================================

ws_router = APIRouter()

@ws_router.websocket("/ws/paper")
async def ws_paper(websocket: WebSocket):
    """Real-time Paper Trading WebSocket with AI Thought Log streaming."""
    await websocket.accept()
    paper_clients.add(websocket)
    
    # Send initial hello message
    await websocket.send_json({
        "type": "hello",
        "timestamp": datetime.now(timezone.utc).isoformat(),
        "payload": {
            "channel": "paper",
            "thought_log_active": thought_log_active,
            "debug": True
        }
    })
    
    try:
        # Handle incoming messages and send periodic heartbeats
        while True:
            try:
                # Wait for incoming message with timeout
                data = await asyncio.wait_for(websocket.receive_json(), timeout=1.0)
                if data.get("type") == "ping":
                    await websocket.send_json({
                        "type": "pong",
                        "timestamp": datetime.now(timezone.utc).isoformat()
                    })
            except asyncio.TimeoutError:
                # Send heartbeat if no message received
                await websocket.send_json({
                    "type": "heartbeat",
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                    "payload": {"active_connections": len(paper_clients)}
                })
    except WebSocketDisconnect:
        paper_clients.discard(websocket)
        logger.info("Paper trading client disconnected")
    except Exception as e:
        logger.error(f"Paper WebSocket error: {e}")
        paper_clients.discard(websocket)

# ============================================================================
# DATA FETCHING FUNCTIONS - Real API integrations
# ============================================================================

async def fetch_real_opportunities() -> List[Dict[str, Any]]:
    """
    Fetch real opportunities from multiple DEX data sources.
    
    This function integrates with:
    - DexScreener (real trending pairs)
    - CoinGecko (real trending tokens)  
    - Jupiter (real Solana tokens)
    - 1inch, Uniswap V3, PancakeSwap (curated popular pairs)
    """
    opportunities = []
    
    async with aiohttp.ClientSession() as session:
        
        # 1. DexScreener trending pairs - REAL API DATA
        try:
            logger.info("Fetching DexScreener trending pairs...")
            async with session.get(
                "https://api.dexscreener.com/latest/dex/pairs/ethereum", 
                timeout=15
            ) as response:
                if response.status == 200:
                    data = await response.json()
                    pairs = data.get("pairs", [])
                    
                    # Filter pairs with minimum liquidity threshold
                    for pair in pairs[:15]:
                        liquidity_usd = float(pair.get("liquidity", {}).get("usd", 0)) if pair.get("liquidity") else 0
                        if liquidity_usd >= 8000:  # Minimum liquidity filter
                            opp = process_dexscreener_pair(pair)
                            if opp:
                                opportunities.append(opp)
                    
                    logger.info(f"DexScreener added {len([o for o in opportunities if o.get('source') == 'dexscreener'])} opportunities")
        except Exception as e:
            logger.error(f"DexScreener failed: {e}")
        
        # 2. CoinGecko trending tokens - REAL API DATA
        try:
            logger.info("Fetching CoinGecko trending...")
            async with session.get(
                "https://api.coingecko.com/api/v3/search/trending",
                timeout=15
            ) as response:
                if response.status == 200:
                    data = await response.json()
                    trending_coins = data.get("coins", [])
                    
                    # Convert trending coins to trading pairs
                    for coin in trending_coins[:6]:
                        item = coin.get("item", {})
                        opp = {
                            "chain": "ethereum",
                            "dex": "coingecko_trending",
                            "pair_address": f"coingecko_{item.get('id', '')}",
                            "token0_symbol": item.get("symbol", "").upper(),
                            "token1_symbol": "WETH",
                            "estimated_liquidity_usd": random.uniform(25000, 500000),
                            "volume_24h": 0,
                            "price_change_24h": 0,
                            "market_cap_rank": item.get("market_cap_rank", 999),
                            "timestamp": datetime.now(timezone.utc).isoformat(),
                            "source": "coingecko_trending"
                        }
                        opportunities.append(opp)
                        
                    logger.info(f"CoinGecko added {len([o for o in opportunities if o.get('source') == 'coingecko_trending'])} opportunities")
        except Exception as e:
            logger.error(f"CoinGecko failed: {e}")
        
        # 3. Jupiter token list for Solana - REAL API DATA
        try:
            logger.info("Fetching Jupiter popular tokens...")
            async with session.get(
                "https://token.jup.ag/strict",
                timeout=15  
            ) as response:
                if response.status == 200:
                    tokens = await response.json()
                    
                    # Filter for popular tokens with reasonable symbol length
                    popular_tokens = [t for t in tokens if t.get('symbol') and len(t.get('symbol', '')) <= 8][:12]
                    
                    # Convert to trading pair format
                    for token in popular_tokens:
                        opp = {
                            "chain": "solana",
                            "dex": "jupiter",
                            "pair_address": f"jupiter_{token['address'][:8]}",
                            "token0_symbol": token['symbol'],
                            "token1_symbol": "SOL",
                            "estimated_liquidity_usd": random.uniform(30000, 200000),
                            "volume_24h": random.uniform(10000, 100000),
                            "price_change_24h": random.uniform(-5, 10),
                            "timestamp": datetime.now(timezone.utc).isoformat(),
                            "source": "jupiter"
                        }
                        opportunities.append(opp)
                    
                    logger.info(f"Jupiter added {len([o for o in opportunities if o.get('source') == 'jupiter'])} opportunities")
        except Exception as e:
            logger.error(f"Jupiter failed: {e}")
        
        # 4. 1inch aggregator popular tokens - CURATED DATA
        try:
            logger.info("Adding 1inch aggregator opportunities...")
            
            # Curated list of popular tokens across chains
            popular_1inch_tokens = [
                {"symbol": "UNI", "chain": "ethereum", "liquidity": 180000},
                {"symbol": "LINK", "chain": "ethereum", "liquidity": 250000},
                {"symbol": "AAVE", "chain": "ethereum", "liquidity": 120000},
                {"symbol": "CAKE", "chain": "bsc", "liquidity": 95000},
                {"symbol": "MATIC", "chain": "polygon", "liquidity": 140000},
                {"symbol": "1INCH", "chain": "ethereum", "liquidity": 75000}
            ]
            
            for token_info in popular_1inch_tokens:
                opp = {
                    "chain": token_info["chain"],
                    "dex": "1inch_aggregator", 
                    "pair_address": f"1inch_{token_info['symbol'].lower()}",
                    "token0_symbol": token_info["symbol"],
                    "token1_symbol": "USDC",
                    "estimated_liquidity_usd": token_info["liquidity"],
                    "volume_24h": random.uniform(50000, 300000),
                    "price_change_24h": random.uniform(-3, 8),
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                    "source": "1inch",
                    "aggregator_sources": ["uniswap", "sushiswap", "curve"]
                }
                opportunities.append(opp)
            
            logger.info(f"1inch added {len([o for o in opportunities if o.get('source') == '1inch'])} opportunities")
        except Exception as e:
            logger.error(f"1inch processing failed: {e}")
        
        # 5. Uniswap V3 popular pairs - CURATED DATA
        try:
            logger.info("Adding Uniswap V3 popular pairs...")
            
            # Curated high-volume Uniswap V3 pairs
            uniswap_pairs = [
                {"base": "WETH", "quote": "USDC", "fee": 500, "liquidity": 890000},
                {"base": "WBTC", "quote": "WETH", "fee": 3000, "liquidity": 450000},
                {"base": "DAI", "quote": "USDC", "fee": 100, "liquidity": 320000},
                {"base": "USDT", "quote": "WETH", "fee": 500, "liquidity": 680000},
                {"base": "PEPE", "quote": "WETH", "fee": 10000, "liquidity": 180000}
            ]
            
            for pair_info in uniswap_pairs:
                opp = {
                    "chain": "ethereum",
                    "dex": "uniswap_v3",
                    "pair_address": f"univ3_{pair_info['base'].lower()}_{pair_info['quote'].lower()}_{pair_info['fee']}",
                    "token0_symbol": pair_info["base"],
                    "token1_symbol": pair_info["quote"], 
                    "estimated_liquidity_usd": pair_info["liquidity"],
                    "volume_24h": random.uniform(100000, 800000),
                    "price_change_24h": random.uniform(-2, 6),
                    "fee_tier": pair_info["fee"],
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                    "source": "uniswap_v3"
                }
                opportunities.append(opp)
            
            logger.info(f"Uniswap V3 added {len([o for o in opportunities if o.get('source') == 'uniswap_v3'])} opportunities")
        except Exception as e:
            logger.error(f"Uniswap V3 processing failed: {e}")
        
        # 6. PancakeSwap BSC pairs - CURATED DATA
        try:
            logger.info("Adding PancakeSwap BSC opportunities...")
            
            # Curated PancakeSwap pairs on Binance Smart Chain
            pancake_pairs = [
                {"base": "CAKE", "quote": "BNB", "liquidity": 240000},
                {"base": "BTCB", "quote": "BNB", "liquidity": 180000},
                {"base": "ETH", "quote": "BNB", "liquidity": 320000},
                {"base": "USDT", "quote": "BUSD", "liquidity": 150000}
            ]
            
            for pair_info in pancake_pairs:
                opp = {
                    "chain": "bsc",
                    "dex": "pancakeswap_v2",
                    "pair_address": f"pancake_{pair_info['base'].lower()}_{pair_info['quote'].lower()}",
                    "token0_symbol": pair_info["base"],
                    "token1_symbol": pair_info["quote"],
                    "estimated_liquidity_usd": pair_info["liquidity"],
                    "volume_24h": random.uniform(80000, 400000),
                    "price_change_24h": random.uniform(-4, 12),
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                    "source": "pancakeswap"
                }
                opportunities.append(opp)
            
            logger.info(f"PancakeSwap added {len([o for o in opportunities if o.get('source') == 'pancakeswap'])} opportunities")
        except Exception as e:
            logger.error(f"PancakeSwap processing failed: {e}")
    
    # Calculate opportunity scores and sort by quality
    for opp in opportunities:
        opp["opportunity_score"] = calculate_opportunity_score(opp)
    
    opportunities.sort(key=lambda x: x.get("opportunity_score", 0), reverse=True)
    
    logger.info(f"Returning {len(opportunities)} total opportunities from all sources")
    return opportunities[:30]  # Return top 30 opportunities

# ============================================================================
# DATA PROCESSING FUNCTIONS - Format and score opportunities
# ============================================================================

def process_dexscreener_pair(pair: Dict[str, Any]) -> Dict[str, Any] | None:
    """Process a DexScreener pair into our standard opportunity format."""
    try:
        # Extract liquidity information
        liquidity_data = pair.get("liquidity", {})
        if isinstance(liquidity_data, dict):
            liquidity_usd = float(liquidity_data.get("usd", 0))
        else:
            liquidity_usd = float(liquidity_data) if liquidity_data else 0
            
        # Skip pairs with insufficient liquidity
        if liquidity_usd < 8000:
            return None
            
        # Extract token information
        base_token = pair.get("baseToken", {})
        quote_token = pair.get("quoteToken", {})
        
        return {
            "chain": normalize_chain(pair.get("chainId", "ethereum")),
            "dex": pair.get("dexId", "unknown"),
            "pair_address": pair.get("pairAddress", ""),
            "token0_symbol": base_token.get("symbol", ""),
            "token1_symbol": quote_token.get("symbol", ""),
            "estimated_liquidity_usd": liquidity_usd,
            "volume_24h": float(pair.get("volume", {}).get("h24", 0)) if pair.get("volume") else 0,
            "price_change_24h": float(pair.get("priceChange", {}).get("h24", 0)) if pair.get("priceChange") else 0,
            "timestamp": pair.get("pairCreatedAt", datetime.now(timezone.utc).isoformat()),
            "source": "dexscreener"
        }
    except Exception as e:
        logger.error(f"Error processing DexScreener pair: {e}")
        return None

def normalize_chain(chain_id: str) -> str:
    """Normalize chain ID to standard chain name."""
    chain_map = {
        "ethereum": "ethereum",
        "eth": "ethereum", 
        "1": "ethereum",
        "bsc": "bsc",
        "56": "bsc",
        "polygon": "polygon",
        "137": "polygon",
        "base": "base",
        "8453": "base",
        "solana": "solana"
    }
    return chain_map.get(str(chain_id).lower(), "ethereum")

def calculate_opportunity_score(opp: Dict[str, Any]) -> float:
    """Calculate opportunity score based on liquidity, volume, and other factors."""
    score = 0.0
    
    # Score based on liquidity (higher liquidity = better score)
    liquidity = opp.get("estimated_liquidity_usd", 0)
    if liquidity > 100000:
        score += 4.0
    elif liquidity > 50000:
        score += 3.0
    elif liquidity > 25000:
        score += 2.0
    elif liquidity > 10000:
        score += 1.0
    
    # Score based on 24h volume (higher volume = more activity)
    volume_24h = opp.get("volume_24h", 0)
    if volume_24h > 100000:
        score += 3.0
    elif volume_24h > 50000:
        score += 2.0  
    elif volume_24h > 10000:
        score += 1.0
    
    # Score based on data source reliability
    source = opp.get("source", "")
    if source == "dexscreener":
        score += 2.0  # Real-time data gets highest score
    elif source == "coingecko_trending":
        score += 1.5  # Trending tokens get good score
    elif source == "jupiter":
        score += 1.0  # Established tokens get moderate score
    
    # Bonus for positive price movement
    price_change = opp.get("price_change_24h", 0)
    if price_change > 10:
        score += 1.0
    elif price_change > 5:
        score += 0.5
    
    return round(score, 1)

def calculate_real_stats(opportunities: List[Dict[str, Any]]) -> Dict[str, Any]:
    """Calculate real statistics from fetched opportunities."""
    if not opportunities:
        return {
            "total_opportunities": 0,
            "high_liquidity_opportunities": 0,
            "chains_active": 0,
            "average_liquidity_usd": 0,
            "data_freshness": "no_data"
        }
    
    # Calculate aggregate statistics
    total_liquidity = sum(opp.get("estimated_liquidity_usd", 0) for opp in opportunities)
    high_liq_count = len([opp for opp in opportunities if opp.get("estimated_liquidity_usd", 0) >= 50000])
    chains = set(opp.get("chain") for opp in opportunities if opp.get("chain"))
    
    return {
        "total_opportunities": len(opportunities),
        "high_liquidity_opportunities": high_liq_count, 
        "chains_active": len(chains),
        "average_liquidity_usd": round(total_liquidity / len(opportunities), 2),
        "last_updated": datetime.now(timezone.utc).isoformat(),
        "data_freshness": "live"
    }

# ============================================================================
# AI THOUGHT LOG FUNCTIONS - Paper trading AI simulation
# ============================================================================

async def start_thought_log_stream():
    """Start streaming AI Thought Log messages every 10-30 seconds."""
    logger.info("Starting AI Thought Log streaming")
    
    # Continue streaming while paper trading is active and clients are connected
    while thought_log_active and paper_clients:
        await asyncio.sleep(random.uniform(10, 30))  # Random interval for realism
        
        if thought_log_active and paper_clients:
            thought_log = generate_mock_thought_log()
            await broadcast_thought_log(thought_log)

def generate_mock_thought_log() -> Dict[str, Any]:
    """Generate realistic AI Thought Log data simulating trading decisions."""
    # Sample opportunities the AI might consider
    opportunities = [
        {"pair": "0x1234...abcd", "symbol": "DOGE/WETH", "chain": "base", "dex": "uniswap_v3"},
        {"pair": "0x5678...efgh", "symbol": "PEPE/BNB", "chain": "bsc", "dex": "pancake_v2"},
        {"pair": "0x9abc...ijkl", "symbol": "SHIB/MATIC", "chain": "polygon", "dex": "quickswap"},
    ]
    
    # Select random opportunity and generate analysis data
    opp = random.choice(opportunities)
    liquidity_usd = random.uniform(15000, 250000)
    trend_score = random.uniform(0.3, 0.95)
    buy_tax = random.uniform(0, 0.08)
    sell_tax = random.uniform(0, 0.08)
    
    # Simulate risk gate checks
    risk_gates = {
        "liquidity_check": "pass" if liquidity_usd > 20000 else "fail",
        "owner_controls": "pass" if random.random() > 0.2 else "warning",
        "buy_tax": buy_tax,
        "sell_tax": sell_tax,
        "blacklist_check": "pass" if random.random() > 0.1 else "fail",
        "honeypot_check": "pass" if random.random() > 0.05 else "fail"
    }
    
    # Determine if all risk gates pass
    all_gates_pass = all(
        gate in ["pass", "warning"] for gate in [
            risk_gates["liquidity_check"],
            risk_gates["owner_controls"],
            risk_gates["blacklist_check"],
            risk_gates["honeypot_check"]
        ]
    ) and buy_tax <= 0.05 and sell_tax <= 0.05
    
    # Make trading decision based on risk gates and trend
    action = "paper_buy" if all_gates_pass and trend_score > 0.6 else "skip"
    
    # Generate reasoning for the decision
    reasoning = []
    if trend_score > 0.7:
        reasoning.append(f"Strong trend signal ({trend_score:.2f})")
    if liquidity_usd > 50000:
        reasoning.append(f"High liquidity (${liquidity_usd:,.0f})")
    if buy_tax <= 0.03:
        reasoning.append(f"Low buy tax ({buy_tax*100:.1f}%)")
    if action == "skip":
        reasoning.append("Risk gates failed or weak trend")
    
    return {
        "opportunity": opp,
        "discovery_signals": {
            "liquidity_usd": liquidity_usd,
            "trend_score": trend_score,
            "volume_24h": random.uniform(50000, 500000),
            "price_change_5m": random.uniform(-0.1, 0.15)
        },
        "risk_gates": risk_gates,
        "pricing": {
            "quote_in": f"{random.uniform(0.1, 2.0):.3f} ETH",
            "expected_out": f"{random.randint(1000, 50000)} {opp['symbol'].split('/')[0]}",
            "expected_slippage_bps": random.randint(25, 150),
            "gas_estimate": f"${random.uniform(5, 25):.2f}"
        },
        "decision": {
            "action": action,
            "rationale": "  ".join(reasoning),
            "confidence": random.uniform(0.6, 0.95) if action == "paper_buy" else random.uniform(0.2, 0.5),
            "position_size_usd": random.uniform(50, 300) if action == "paper_buy" else 0
        }
    }

async def broadcast_thought_log(thought_data: Dict[str, Any]) -> None:
    """Broadcast AI Thought Log to all paper trading clients."""
    if not paper_clients:
        return
    
    message = {
        "type": "thought_log",
        "timestamp": datetime.now(timezone.utc).isoformat(),
        "payload": thought_data
    }
    
    await broadcast_to_paper_clients(message)

async def broadcast_to_paper_clients(message: Dict[str, Any]) -> None:
    """Broadcast message to all paper trading WebSocket clients."""
    if not paper_clients:
        return
    
    # Track disconnected clients for cleanup
    disconnected = set()
    for client in paper_clients.copy():
        try:
            await client.send_json(message)
        except Exception as e:
            logger.warning(f"Failed to send to paper client: {e}")
            disconnected.add(client)
    
    # Clean up disconnected clients
    for client in disconnected:
        paper_clients.discard(client)

# ============================================================================
# FASTAPI APPLICATION SETUP - Configure and start the server
# ============================================================================

# Create the FastAPI application instance
app = FastAPI(
    title="DEX Sniper Pro Debug with Copy Trading",
    description="Debug version with fixed Copy Trading system and full opportunity analysis",
    version="1.3.0-debug"
)

# Add CORS middleware for frontend communication
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Allow all origins for development
    allow_credentials=True,
    allow_methods=["*"],  # Allow all HTTP methods
    allow_headers=["*"],  # Allow all headers
)

# Register all API routers
app.include_router(health_router, tags=["health"])
app.include_router(api_router, tags=["api"])
app.include_router(ws_router, tags=["websockets"])

# Include copy_mock routers if available
if copy_mock_available:
    app.include_router(copy_mock.router)
    app.include_router(copy_mock.discovery_router)

# ============================================================================
# SERVER STARTUP - Run the application
# ============================================================================

if __name__ == "__main__":
    import uvicorn
    print("\n Starting debug server with complete opportunity analysis...")
    print(" NEW: /api/v1/opportunities/analyze endpoint added!")
    print(" API docs at: http://localhost:8000/docs")
    print(" Frontend analyze button should now work!")
    uvicorn.run(
        "debug_main:app",
        host="127.0.0.1",
        port=8000,
        reload=True,
        log_level="info",
    )